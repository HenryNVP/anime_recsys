{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "74f233cd",
      "metadata": {
        "id": "74f233cd",
        "outputId": "8479f0c5-a031-4ae4-e52c-6cf96aee83dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b28af544",
      "metadata": {
        "id": "b28af544",
        "outputId": "0cd21330-ba2c-4d80-b0ab-d0c89b123db7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'anime_recsys'...\n",
            "remote: Enumerating objects: 156, done.\u001b[K\n",
            "remote: Counting objects: 100% (156/156), done.\u001b[K\n",
            "remote: Compressing objects: 100% (119/119), done.\u001b[K\n",
            "remote: Total 156 (delta 57), reused 100 (delta 29), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (156/156), 105.10 KiB | 15.01 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n",
            "/content/anime_recsys\n"
          ]
        }
      ],
      "source": [
        "REPO = \"https://github.com/HenryNVP/anime_recsys.git\"\n",
        "!git clone $REPO\n",
        "\n",
        "import os\n",
        "%cd anime_recsys\n",
        "\n",
        "!pip -q install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2c87539a",
      "metadata": {
        "id": "2c87539a",
        "outputId": "4ec436e1-73c3-4461-9143-60400393a589",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project root: /content/anime_recsys\n",
            "Paths: {'data_raw': '/content/anime_recsys/data_raw', 'data_clean': '/content/anime_recsys/data_clean', 'outputs': '/content/anime_recsys/outputs'}\n"
          ]
        }
      ],
      "source": [
        "import os, sys, json, pickle, numpy as np, pandas as pd\n",
        "\n",
        "PROJECT_ROOT = os.getcwd()  # adjust if needed\n",
        "DATA_RAW   = os.path.join(PROJECT_ROOT, \"data_raw\")\n",
        "DATA_CLEAN = os.path.join(PROJECT_ROOT, \"data_clean\")\n",
        "OUTPUTS    = os.path.join(PROJECT_ROOT, \"outputs\")\n",
        "\n",
        "for p in [DATA_RAW, DATA_CLEAN, OUTPUTS]:\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "# ensure package import works (recsys/)\n",
        "if PROJECT_ROOT not in sys.path:\n",
        "    sys.path.append(PROJECT_ROOT)\n",
        "\n",
        "print(\"Project root:\", PROJECT_ROOT)\n",
        "print(\"Paths:\", {\"data_raw\": DATA_RAW, \"data_clean\": DATA_CLEAN, \"outputs\": OUTPUTS})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eef40cf6",
      "metadata": {
        "id": "eef40cf6"
      },
      "outputs": [],
      "source": [
        "# Upload anime.csv, rating.csv\n",
        "os.makedirs(\"data_raw\", exist_ok=True)\n",
        "\n",
        "from google.colab import files\n",
        "print(\"Upload anime.csv and rating.csv\")\n",
        "uploaded = files.upload()\n",
        "for name in uploaded.keys():\n",
        "    if name.endswith(\".csv\"):\n",
        "        !mv $name data/\n",
        "!ls -lh data || true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e9e9118",
      "metadata": {
        "id": "7e9e9118"
      },
      "outputs": [],
      "source": [
        "# Preprocess to data_clean/ (70/15/15)\n",
        "!python scripts/preprocess.py --raw_dir data_raw --clean_dir data_clean --min_user_inter 5 --min_item_inter 5 --seed 42 --train_ratio 0.70 --val_ratio 0.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19547cef",
      "metadata": {
        "id": "19547cef"
      },
      "outputs": [],
      "source": [
        "print(json.dumps(json.load(open(os.path.join(DATA_CLEAN, \"stats.json\"))), indent=2)[:800])\n",
        "pd.read_parquet(os.path.join(DATA_CLEAN, \"train.parquet\")).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11dd3926",
      "metadata": {
        "id": "11dd3926"
      },
      "source": [
        "## Basline models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef3b5701",
      "metadata": {
        "id": "ef3b5701"
      },
      "source": [
        "### Popularity model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bcddace",
      "metadata": {
        "id": "9bcddace"
      },
      "outputs": [],
      "source": [
        "# Preprocess data and run baseline popularity model\n",
        "!python -m recsys.train --trainer popularity --data_dir data_clean --outputs outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46c88220",
      "metadata": {
        "id": "46c88220"
      },
      "source": [
        "### Item-based colaborative filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca1912a0",
      "metadata": {
        "id": "ca1912a0"
      },
      "outputs": [],
      "source": [
        "# Train itemknn model\n",
        "!python -m recsys.train --trainer itemknn --data_dir data_clean --outputs outputs --max_neighbors 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e95fb8c3",
      "metadata": {
        "id": "e95fb8c3"
      },
      "outputs": [],
      "source": [
        "#@title Sweep k neighbors and plot (val)\n",
        "!python scripts/tune_itemknn.py --outputs outputs --split val --eval_k 10 --max_k 200 --step 10 --csv_out itemknn_tuning.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc42d6ff",
      "metadata": {
        "id": "dc42d6ff"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"itemknn_tuning.csv\")\n",
        "best_k = int(df.sort_values(by=\"NDCG@10\", ascending=False).iloc[0][\"use_k\"])\n",
        "best_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "679e9f5f",
      "metadata": {
        "id": "679e9f5f"
      },
      "outputs": [],
      "source": [
        "#@title Test ItemKNN with best_k\n",
        "!python -m recsys.eval --model itemknn --outputs outputs --split test --k 10 --use_k_neighbors {best_k}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87072275",
      "metadata": {
        "id": "87072275"
      },
      "source": [
        "## NeuMF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d5be240",
      "metadata": {
        "id": "7d5be240"
      },
      "outputs": [],
      "source": [
        "#@title Train NeuMF\n",
        "!python -m recsys.train --trainer neumf --data_dir data_clean --outputs outputs --epochs 8 --batch_size 131072 --neg_k 4 --emb_gmf 64 --emb_mlp 64 --mlp_layers 256,128,64 --patience 2 --k_eval 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "140dd0cf",
      "metadata": {
        "id": "140dd0cf"
      },
      "outputs": [],
      "source": [
        "#@title Eval NeuMF on val and test\n",
        "!python -m recsys.eval --model neumf --outputs outputs --split val --k 10\n",
        "!python -m recsys.eval --model neumf --outputs outputs --split test --k 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c6ea5c9",
      "metadata": {
        "id": "0c6ea5c9"
      },
      "outputs": [],
      "source": [
        "#@title Train Hybrid NeuMF (optional)\n",
        "!python -m recsys.train --trainer hybrid --data_dir data_clean --outputs outputs --epochs 8 --batch_size 131072 --neg_k 4 --emb_gmf 32 --emb_mlp 32 --mlp_layers 256,128,64 --patience 2 --k_eval 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aceb1e1b",
      "metadata": {
        "id": "aceb1e1b"
      },
      "outputs": [],
      "source": [
        "#@title Eval Hybrid NeuMF\n",
        "!python -m recsys.eval --model hybrid --outputs outputs --split val --k 10\n",
        "!python -m recsys.eval --model hybrid --outputs outputs --split test --k 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b52e436",
      "metadata": {
        "id": "8b52e436"
      },
      "outputs": [],
      "source": [
        "#@title NeuMF tuning sweep (small grid; early stopping on val NDCG@10)\n",
        "!python scripts/tune_neumf.py \\\n",
        "  --data_dir data_clean --outputs outputs \\\n",
        "  --epochs 8 --patience 2 --k_eval 10 \\\n",
        "  --emb_gmf_grid 32,64 \\\n",
        "  --emb_mlp_grid 32,64 \\\n",
        "  --mlp_grid 256-128-64,512-256-128 \\\n",
        "  --lr_grid 0.003,0.001 \\\n",
        "  --negk_grid 2,4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ce56be7",
      "metadata": {
        "id": "8ce56be7"
      },
      "source": [
        "## Compare all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eb7af34",
      "metadata": {
        "id": "5eb7af34"
      },
      "outputs": [],
      "source": [
        "#@title Compare popularity, itemknn(best_k), neumf (and hybrid if trained)\n",
        "!python scripts/compare_all.py --outputs outputs --Ks 5,10,20 --use_k_neighbors {best_k}\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}